<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Wllama Chatbot</title>
    <style>
        body {
            font-family: sans-serif;
            display: flex;
            flex-direction: column;
            height: 100vh;
            margin: 0;
            background-color: #f4f4f4;
        }
        #chatbox {
            flex-grow: 1;
            overflow-y: auto;
            padding: 20px;
            border-bottom: 1px solid #ccc;
            background-color: #fff;
            margin-bottom: 10px;
        }
        .message {
            margin-bottom: 15px;
            padding: 10px 15px;
            border-radius: 15px;
            max-width: 80%;
            line-height: 1.4;
        }
        .user-message {
            background-color: #dcf8c6;
            align-self: flex-end;
            margin-left: auto; /* Aligns to the right */
        }
        .bot-message {
            background-color: #e0e0e0;
            align-self: flex-start;
             margin-right: auto; /* Aligns to the left */
        }
        .message strong {
            display: block;
            margin-bottom: 5px;
            font-size: 0.9em;
            color: #555;
        }
        #input-area {
            display: flex;
            padding: 10px;
            border-top: 1px solid #ccc;
            background-color: #eee;
        }
        #userInput {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            margin-right: 10px;
        }
        #sendButton {
            padding: 10px 20px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        #sendButton:disabled {
            background-color: #aaa;
            cursor: not-allowed;
        }
        #sendButton:hover:not(:disabled) {
             background-color: #0056b3;
        }
        #status {
            padding: 5px 10px;
            font-size: 0.9em;
            color: #666;
            text-align: center;
            background-color: #f0f0f0;
            min-height: 1.2em; /* Reserve space */
        }
         /* Simple loading spinner */
        .loader {
            border: 4px solid #f3f3f3; /* Light grey */
            border-top: 4px solid #3498db; /* Blue */
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 1s linear infinite;
            display: inline-block; /* Or block/flex depending on layout */
            margin-left: 10px; /* Example spacing */
            vertical-align: middle;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div id="status">Initializing...</div>
    <div id="chatbox">
        <!-- Chat messages will appear here -->
    </div>
    <div id="input-area">
        <input type="text" id="userInput" placeholder="Type your message..." disabled>
        <button id="sendButton" disabled>Send</button>
    </div>
    <script type="module">
        // --- Configuration ---
        // Using jsdelivr CDN for the wllama library components - VERSION 2.3.1
        const WLLAMA_INDEX_JS_URL = 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.3.1/esm/index.js';
        // We will now define the paths to the WASM files directly using the CDN
        const WLLAMA_CDN_BASE = 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.3.1/esm/';
        const CONFIG_PATHS = {
          'single-thread/wllama.wasm': `${WLLAMA_CDN_BASE}single-thread/wllama.wasm`,
          'multi-thread/wllama.wasm' : `${WLLAMA_CDN_BASE}multi-thread/wllama.wasm`,
          // You might need the worker if multi-threading is used, let's include it:
          'multi-thread/wllama.worker.mjs' : `${WLLAMA_CDN_BASE}multi-thread/wllama.worker.mjs`
        };


        const MODEL_REPO = 'lmstudio-community/gemma-3-1B-it-qat-GGUF';
        const MODEL_FILENAME = 'gemma-3-1B-it-QAT-Q4_0.gguf'; // ~765MB Q4_K_M quantization
        
        // --- DOM Elements ---
        const chatbox = document.getElementById('chatbox');
        const userInput = document.getElementById('userInput');
        const sendButton = document.getElementById('sendButton');
        const statusDiv = document.getElementById('status');

        let wllamaInstance = null;
        let modelLoaded = false;

        // --- Helper Functions ---
        function displayMessage(sender, message) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message', sender === 'user' ? 'user-message' : 'bot-message');
            updateMessageContent(messageDiv, sender, message); // Use a helper for content setting
            chatbox.appendChild(messageDiv);
            chatbox.scrollTop = chatbox.scrollHeight;
            return messageDiv; // Return the element
        }

        // Helper to set message content (handles formatting)
        function updateMessageContent(messageDiv, sender, text) {
             // Basic Markdown-like formatting
            let formattedText = text.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            formattedText = formattedText.replace(/\*(.*?)\*/g, '<em>$1</em>');
            formattedText = formattedText.replace(/\n/g, '<br>'); // Handle newlines

             // Prevent potential model output like <end_of_turn> from being rendered raw
             formattedText = formattedText.replace(/</g, "<").replace(/>/g, ">");
             // Re-allow specific HTML tags we use
             formattedText = formattedText.replace(/<strong>/g, '<strong>').replace(/<\/strong>/g, '</strong>');
             formattedText = formattedText.replace(/<em>/g, '<em>').replace(/<\/em>/g, '</em>');
             formattedText = formattedText.replace(/<br>/g, '<br>');


            messageDiv.innerHTML = `<strong>${sender === 'user' ? 'You' : 'Bot'}</strong>${formattedText}`;
            // Scroll again in case content update changes height significantly
            chatbox.scrollTop = chatbox.scrollHeight;
        }


        function setStatus(text, showSpinner = false) {
            statusDiv.innerHTML = text + (showSpinner ? ' <div class="loader"></div>' : '');
        }

        function enableInput() {
            userInput.disabled = false;
            sendButton.disabled = false;
            userInput.focus();
        }

        function disableInput() {
            userInput.disabled = true;
            sendButton.disabled = true;
        }


        // --- Core Logic ---
        async function initializeWllama() {
            try {
                setStatus('Loading wllama library...');
                console.log('Importing Wllama core from CDN...');
                // Dynamically import only the main Wllama class from CDN
                const { Wllama } = await import(WLLAMA_INDEX_JS_URL);
                console.log('Wllama core imported.');

                setStatus('Initializing wllama with CDN paths...');
                // *** Use the manually defined CONFIG_PATHS ***
                wllamaInstance = new Wllama(CONFIG_PATHS);
                console.log('Wllama instance created with manual CDN paths.');

                const progressCallback = ({ loaded, total }) => {
                    const progressPercentage = total > 0 ? Math.round((loaded / total) * 100) : 0;
                    setStatus(`Downloading model... ${progressPercentage}% (${(loaded / 1024 / 1024).toFixed(1)} / ${(total / 1024 / 1024).toFixed(1)} MB)`, true);
                     console.log(`Model download progress: ${progressPercentage}%`);
                };

                setStatus('Starting model download (this may take a while)...', true);
                 console.log(`Loading model: ${MODEL_REPO}/${MODEL_FILENAME}`);

                await wllamaInstance.loadModelFromHF(
                    MODEL_REPO,
                    MODEL_FILENAME,
                    {
                        progressCallback,
                        n_ctx:  4 * 1024, 
                        cache_type_k: 'q4_0',
                        n_threads: 4,
                        // Optional: Increase parallel downloads if desired and supported by server/browser
                        // parallelDownloads: 5,
                        // Explicitly allow cross-origin loading for WASM workers if needed
                        // (though fetching from same CDN *should* be fine, sometimes helps)
                         config: {
                             assetPath: WLLAMA_CDN_BASE + 'multi-thread/',
                             n_ctx:  5* 1024, // Context size for the model
                             cache_type_k: 'q4_0',
                             n_ctx_per_seq: 4096, // Context size for each sequence
                             n_threads: 4, // Number of threads to use (adjust based on your CPU)
                             llama_context:4096, 
                         }
                    }
                );

                modelLoaded = true;
                setStatus('Model loaded successfully! Ready to chat.');
                console.log('Model loaded.');
                enableInput();
                displayMessage('bot', 'Hello! I am ready. Ask me anything.');

            } catch (error) {
                console.error('Initialization or Model Loading Error:', error);
                // Check for specific errors like Cross-Origin-Isolation problems
                if (error.message && error.message.includes('SharedArrayBuffer')) {
                     setStatus(`Error: ${error.message}. Ensure your server sends COOP/COEP headers for multi-threading.`);
                } else {
                    setStatus(`Error: ${error.message || 'Failed to initialize or load model.'}`);
                }
                disableInput(); // Keep input disabled on error
            }
        }

        // --- UPDATED and CORRECTED handleSendMessage function ---
        async function handleSendMessage() {
            const message = userInput.value.trim();
            if (!message || !wllamaInstance || !modelLoaded) {
                return;
            }

            displayMessage('user', message); // Display user message
            userInput.value = '';
            disableInput();
            setStatus('Bot is thinking...', true);

            // Create Placeholder for Bot Response
            const botMessageDiv = displayMessage('bot', '...'); // Start with placeholder

            try {
                const formattedPrompt = `<start_of_turn>user\n${message}<end_of_turn>\n<start_of_turn>model\n`;
                console.log("Sending prompt to wllama:", formattedPrompt);

                // --- CORRECTED onNewToken Callback ---
                // Signature is (token: number, piece: Uint8Array | string, currentText: string)
                const onNewTokenCallback = (token, piece, currentText) => {
                    // Use the THIRD argument 'currentText' which is the accumulated string
                    if (typeof currentText === 'string') {
                        updateMessageContent(botMessageDiv, 'bot', currentText);
                        // console.log("Token:", token, "Piece:", piece, "Current Text:", currentText); // Debugging if needed
                    } else {
                        // Fallback or error handling if currentText isn't a string (shouldn't happen based on types)
                        console.warn("Received non-string currentText in onNewToken:", currentText);
                    }
                };

                // Call createCompletion with the Corrected Callback
                const outputText = await wllamaInstance.createCompletion(formattedPrompt, {
                    nPredict: 1024,
                    sampling: {
                        temp: 0.0,
                        top_k: 5,
                        top_p: 0.90,
                        // stop: ["<end_of_turn>", "<start_of_turn>"]
                    },
                    onNewToken: onNewTokenCallback // Pass the callback here
                });

                console.log("Streaming finished. Final output:", outputText);

                // Final Update - outputText should be the final string
                if (typeof outputText === 'string') {
                     let cleanedOutput = outputText.replace(/<end_of_turn>/g, '').trim();
                    updateMessageContent(botMessageDiv, 'bot', cleanedOutput || "(No response generated)");
                } else {
                     console.error("Final outputText was not a string:", outputText);
                     updateMessageContent(botMessageDiv, 'bot', "(Error: Invalid final output format)");
                }


                setStatus('Ready.');
                enableInput();

            } catch (error) {
                console.error('Error during completion:', error);
                setStatus(`Error: ${error.message || 'Failed to generate response.'}`);
                // Update the bot message div with an error indication
                updateMessageContent(botMessageDiv, 'bot', 'Sorry, I encountered an error trying to respond.');
                enableInput(); // Re-enable input even on error
            }
        }

        // --- Event Listeners ---
        sendButton.addEventListener('click', handleSendMessage);
        userInput.addEventListener('keypress', (event) => {
            if (event.key === 'Enter' && !sendButton.disabled) {
                handleSendMessage();
            }
        });

        // --- Start Initialization ---
        initializeWllama();

    </script>
</body>
</html>
